{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e22cdeae08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data=df , palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Stand\n",
    "ardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284802</td>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284803</td>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284804</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284805</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284806</td>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]\n",
    "#df.columns=='Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns=='Class'\n",
    "#df_at = df[['Amount', 'Time']]\n",
    "#df = df.drop(['Amount', 'Time'], axis=1)\n",
    "X = df.loc[:, df.columns!='Class']\n",
    "y = df.loc[:, df.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149.62],\n",
       "       [  2.69],\n",
       "       [378.66],\n",
       "       ...,\n",
       "       [ 67.88],\n",
       "       [ 10.  ],\n",
       "       [217.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_at['Amount'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burada normalizasyon yapiyoruz, 'Amount' sutunundaki butun degerlerin ortalamasini 0 uzerine cekip \n",
    "df['normal_amount'] = StandardScaler().fit_transform(df_at['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-df['normal_amount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.34961925087359"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Amount.mean()\n",
    "#df.normal_amount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25691.16"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_at.Amount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normal_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99982415 0.64539007]\n",
      "0.9992392589211521\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(recall_score(y_test,y_pred,average=None))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99985931 0.61904762]\n",
      "0.999204147794436\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(recall_score(y_test,y_pred,average=None))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada accuracy degeri cok yuksek ancak recall degeri %60 larda.\n",
    "Recall degerini yukseltmek icin undersampling metoduyla fraud olmayan degerlerin sayisini fraud olanlara esitleyecek sekilde rastgele secim yapiyoruz. Modeli bu sekilde train edince ortaya daha iyi bir recall elde edecegimizi dusunuyoruz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_fraud = len(df[df['Class'] ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_indices = df[df['Class'] ==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(non_fraud_indices, no_of_fraud, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = df[df['Class'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample_indices = np.concatenate([fraud_indices, random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample = df.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e233a2c4c8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data=under_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istedigimiz sekle soktugumuz datayi simdi yeniden logistic regresyona sokarak yeni bir model olusturacagiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = under_sample.loc[:,under_sample.columns != 'Class']\n",
    "y_under = under_sample.loc[:,under_sample.columns == 'Class']\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251700680272109\n",
      "0.9358108108108109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr_under = LogisticRegression()\n",
    "lr_under.fit(X_under_train,y_under_train)\n",
    "y_under_pred = lr_under.predict(X_under_test)\n",
    "print(recall_score(y_under_test,y_under_pred))\n",
    "print(accuracy_score(y_under_test,y_under_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada aldigimiz degerler sadece \"under_sample\" datasinin recall ve accuracy degerleri. simdi bu modeli butun data uzerinde test edecek ve sonucun ilk aldigimiz recall degeriyle karsilastirmasini yapacagiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251700680272109\n",
      "0.9577847219783949\n"
     ]
    }
   ],
   "source": [
    "y_pred_full = lr_under.predict(X_test)\n",
    "print(recall_score(y_test,y_pred_full))\n",
    "print(accuracy_score(y_test,y_pred_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goruldugu uzere bu model data onceki modelden cok daha iyi bir recall degeri sagliyor, accuracy de de cok bir fark olusturmadan. Bizim burada manuel olarak yaptigimiz undersampling islemini sci-kit learn librarisindeki \"LogisticRegression\" fonksiyonunu kullanarak cok daha kisa surede yapabiliriz: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\aileninferdi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9115646258503401\n",
      "0.9771777676345634\n"
     ]
    }
   ],
   "source": [
    "lr_balanced = LogisticRegression(class_weight = 'balanced')\n",
    "lr_balanced.fit(X_train,y_train)\n",
    "y_balanced_pred = lr_balanced.predict(X_test)\n",
    "print(recall_score(y_test,y_balanced_pred))\n",
    "print(accuracy_score(y_test,y_balanced_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_value = confusion_matrix(y_test,y_balanced_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83359,  1937],\n",
       "       [   13,   134]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
